# Visual Imagery Decoding

### Neural Decoding of Visual Imagery During Sleep

doi: https://www.science.org/doi/10.1126/science.1234330

news: https://www.theguardian.com/science/neurophilosophy/2013/apr/05/brain-scans-decode-dream-content

Reading Dreams

> How specific visual dream contents are represented by brain activity is unclear. Machine-learning–based analyses can decode the stimulus- and task-induced brain activity patterns that represent specific visual contents. Horikawa et al. (p. [639](https://doi.org/10.1126/science.1234330), published online 4 April) examined patterns of brain activity during dreaming and compared these to waking responses to visual stimuli. The findings suggest that the visual content of dreams is represented by the same neural substrate as observed during awake perception.

Abstract

>Visual imagery during sleep has long been a topic of persistent speculation, but its private nature has hampered objective analysis. Here we present a neural decoding approach in which machine-learning models predict the contents of visual imagery during the sleep-onset period, given measured brain activity, by discovering links between human functional magnetic resonance imaging patterns and verbal reports with the assistance of lexical and image databases. Decoding models trained on stimulus-induced brain activity in visual cortical areas showed accurate classification, detection, and identification of contents. Our findings demonstrate that specific visual experience during sleep is represented by brain activity patterns shared by stimulus perception, providing a means to uncover subjective contents of dreaming using objective neural measurement.

sensors

> used [functional magnetic resonance imaging](http://www.guardian.co.uk/science/neurophilosophy/2013/jan/04/big-picture-inside-the-brain1) (fMRI) to scan the brains of three people as they slept, while simultaneously recording their brain waves using electroencephalography (EEG).

user study

> The researchers woke the participants whenever they detected the brain wave patterns associated with the earliest stages of sleep, asked them what they had just dreamed about, and then let them go back to sleep. This was done in three-hour blocks, and repeated between 7 and 10 times, on different days, for each participant.

> During each block, participants were woken up 10 times per hour. Each volunteer reported having visual dreams 6 or 7 times every hour, giving the researchers a total of around 200 dream reports from each of them.

dream report

>Most of the dreams reflected everyday experiences. "I had a dream [that I was at] a bakery. I took a roll … then went out on the street, and saw a person taking a photograph," reported one participant. "I saw a big bronze statue … on a small hill [and] below the hill there were houses, streets, and trees," said another. Some contained slightly more unusual content, such as meeting a film star or being in a recording studio.

> Kamitani and his colleagues used a lexical database called [WordNet](http://wordnet.princeton.edu/) to extract key words from the participants' verbal reports, and picked 20 categories — such as "car", "male", "female", and "computer" — that appeared most frequently in their dream reports. They then selected photos representing each category, scanned the participants' brains again while they viewed the images, and compared brain activity patterns with those recorded just before the participants were woken up.

analysis

> The researchers analysed activity in brain areas V1, V2 and V3, which are involved in the earliest stages of visual processing and encode basic features of visual scenes, such as contrast and the orientation of edges. They also looked at several other regions that are involved in higher order visual functions, such as object recognition.

result

>could [decode and reconstruct visual images](http://scienceblogs.com/neurophilosophy/2008/12/12/visual-images-reconstructed-from-brain-activity/) from the activity in these brain areas. 

